Hemos resuelto el problema de escalado con el autoescalado de Amazon EC2. Pero ahora tenemos un pequeño problema de tráfico, ¿no? Echemos un vistazo a la situación. Cuando los clientes entran en la cafetería, ahora mismo tienen tres opciones para saber con qué cajero hablar, para hacer un pedido, y curiosamente, la mayoría de ellos están haciendo cola en una línea, provocando una distribución desigual de clientes por línea. Aunque tenemos otros cajeros esperando para tomar pedidos, están parados sin hacer nada. Los clientes entran y no están seguros exactamente de por dónde dirigir su pedido, ayudaría mucho si añadiéramos un anfitrión a la situación. Un anfitrión se sitúa en la puerta y cuando los clientes entran en la cafetería, les indica a qué fila deben dirigirse para hacer su pedido. El anfitrión vigila a los cajeros que toman los pedidos y cuenta el número de personas que hay en la fila, cada cajero está atendiendo. A continuación, dirigirá a los nuevos clientes al cajero que tenga la cola más corta como el menos atascado. De este modo, permite que las colas sean uniformes entre los cajeros y ayuda a los clientes a ser atendidos de la manera más eficiente posible. La misma idea se aplica a su entorno AWS. Cuando tiene múltiples instancias EC2 todas ejecutando los mismos programas sirven al mismo propósito, y llega una solicitud, ¿cómo sabe esa solicitud a qué instancia EC2 dirigirse? ¿Cómo puede asegurarse de que hay una distribución uniforme de la carga de trabajo entre las instancias EC2. No sólo una está respaldada mientras las otras están ociosas, sentadas. Usted necesita una manera de enrutar las solicitudes a instancias para procesar esa solicitud. Lo que necesita para resolver esto se llama balanceo de carga. Un balanceador de carga es una aplicación, toma las solicitudes y las enruta a las instancias para ser procesadas. Ahora, hay muchos balanceadores de carga off the shelf que funcionan muy bien en AWS. Si usted tiene un sabor favorito que ya hace exactamente lo que quiere, entonces siéntase libre de seguir usándolo. En cuyo caso, será hasta su equipo de operaciones para instalar, administrar, actualizar, escalar, manejar la conmutación por error, y la disponibilidad. Es factible, lo más probable es que lo que realmente necesite sea simplemente distribuir adecuadamente el tráfico en un sistema de alto rendimiento, rentable, altamente disponible, escalable automáticamente que pueda configurar y olvidarse. Presentación del equilibrio de carga elástico. El equilibrio de carga elástico, o ELB, es uno de los primeros servicios gestionados importantes de los que vamos a hablar en este curso. Está diseñado para abordar el trabajo pesado e indiferenciado del equilibrio de carga. Para ilustrar este punto, necesito alejarme un poco aquí. Para empezar, el equilibrio de carga elástico es una construcción regional y explicaremos más lo que eso significa en vídeos posteriores. Pero el valor clave para usted es que debido a que se ejecuta a nivel de región en lugar de en instancias EC2 individuales, el servicio está automáticamente altamente disponible sin ningún esfuerzo adicional por su parte. ELB es automáticamente escalable. A medida que su tráfico crece, ELB está diseñado para manejar el rendimiento adicional sin cambiar el coste por hora. Cuando su flota EC2 se autoescala a medida que cada instancia entra en línea, el servicio de autoescalado simplemente hace saber al servicio de equilibrio de carga elástica que está listo para manejar el tráfico y listo. Una vez que la flota se autoescala, ELB primero detiene todo el tráfico nuevo y espera a que las solicitudes existentes se completen para drenarse. Una vez que lo hacen, entonces el motor de autoescalado puede terminar las instancias sin interrupción para los clientes existentes. El ELB no sólo se utiliza para el tráfico externo. Echemos un vistazo al nivel de pedidos y a cómo se comunica con el nivel de producción. En este momento, cada instancia de frontend es consciente de cada instancia de backend. Si una nueva instancia backend entra en línea en esta arquitectura actual, tendría que decirle a cada instancia front-end que ahora puede aceptar tráfico. Esto ya es bastante complicado con sólo media docena de instancias. Ahora imagine que tiene potencialmente cientos de instancias en ambos niveles, cada nivel cambiando constantemente en función de la demanda. Mantenerlas en red de forma eficiente es imposible. Bien, solucionamos el caos de tráfico del back-end también con un ELB. Como el ELB es regional, es una única URL que utiliza cada instancia del front-end. Entonces el ELB dirige el tráfico a el back-end que tenga menos peticiones pendientes. Ahora, si el back-end escala, una vez que la nueva instancia está lista, simplemente le dice al ELB que puede recibir tráfico y se pone a trabajar. El front-end no sabe y no le importa cuántas instancias del back-end se están ejecutando. Esta es una verdadera arquitectura desacoplada. Hay aún más que el ELB puede hacer que aprenderemos más adelante, pero esto es lo suficientemente bueno por ahora. La clave está en elegir la herramienta adecuada para el trabajo adecuado, que es una de las razones por las que AWS ofrece tantos servicios diferentes. Por ejemplo, la comunicación back-end. Hay muchas maneras de manejarla, y el ELB es sólo un método. A continuación, hablaremos de algunos otros servicios que podrían funcionar incluso mejor para algunas arquitecturas.